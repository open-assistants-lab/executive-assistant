# Executive Assistant Technical Architecture Documentation

**Version:** 1.1.0
**Last Updated:** January 29, 2026
**Project:** Executive Assistant - Multi-channel AI Agent Platform

**Recent Updates (January 2026):**
- ‚úÖ Migrated to LangChain agent runtime (removed custom nodes.py)
- ‚úÖ Implemented token usage tracking for HTTP channel (OpenAI/Anthropic)
- ‚úÖ Added comprehensive middleware stack (summarization, retry, status updates)
- ‚úÖ Fixed progressive disclosure bug (all 71 tools now available by default)
- ‚úÖ Added ThreadContextMiddleware for async context propagation
- ‚úÖ Enhanced error logging with comprehensive tracebacks
- ‚úÖ Fixed HTTP channel non-streaming endpoint
- ‚úÖ HTTP channel now bypasses allowlist (frontend auth pattern)

---

## Table of Contents

1. [Project Overview](#project-overview)
2. [Technology Stack](#technology-stack)
3. [Architecture Overview](#architecture-overview)
4. [Code Structure](#code-structure)
5. [Core Components](#core-components)
6. [Data Flow](#data-flow)
7. [Storage Architecture](#storage-architecture)
8. [Key Libraries & Frameworks](#key-libraries--frameworks)
9. [Configuration Management](#configuration-management)
10. [Deployment Architecture](#deployment-architecture)
11. [Testing Strategy](#testing-strategy)

---

## Project Overview

Executive Assistant is a **multi-channel AI agent platform** built on LangGraph that implements a ReAct (Reasoning + Acting) agent pattern. It provides intelligent task execution across multiple communication channels (Telegram, HTTP) with persistent state management, privacy-first multi-tenant storage, and a comprehensive toolkit for data operations.

**Key Characteristics:**
- **LangChain Agent Runtime**: High-level agent creation with middleware stack
- **ReAct Agent Pattern**: Reasoning ‚Üí Action ‚Üí Observation cycle
- **Multi-Channel Support**: Telegram bot and HTTP REST API with SSE streaming
- **Privacy-First Storage**: Thread-only context with per-thread data isolation
- **Tool-Based Intelligence**: All 71 tools available in every conversation
- **State Persistence**: PostgreSQL-backed checkpointing for conversation memory
- **Token Tracking**: Automatic usage monitoring for cost control (provider-dependent)
- **Production-Ready**: Middleware stack with summarization, retry logic, status updates, and call limits

---

## Technology Stack

### Core Frameworks
| Category | Technology | Purpose |
|----------|-----------|---------|
| **Orchestration** | LangGraph v1.0.6+ | Agent workflow/state management |
| **LLM Abstraction** | LangChain v0.3.27+ | Unified LLM interface |
| **LLM Runtime** | LangGraph-Prebuilt v1.0.6+ | Prebuilt agent components |
| **HTTP Server** | FastAPI v0.115.0+ | REST API with streaming |
| **Async Runtime** | uvicorn | ASGI server |

### LLM Providers
- **Anthropic**: Claude models (Claude Haiku/Sonnet)
- **OpenAI**: GPT models (GPT-4o, GPT-4o-mini)
- **Zhipu AI**: GLM-4 models
- **Ollama**: Local/Cloud OpenAI-compatible models

### Data Storage
| Type | Technology | Purpose |
|------|-----------|---------|
| **State/Checkpoint** | PostgreSQL (via asyncpg) | Conversation persistence |
| **Vector Database** | LanceDB | Semantic search/knowledge base |
| **Tabular Data** | SQLite (sqlite_db_storage.py, tdb_tools.py) | Transactional, permanent data (timesheets, CRM, tasks) |
| **Memories** | SQLite + FTS5 (mem_storage.py) | Embedded memories with full-text search |
| **File Storage** | Local filesystem | Document/file storage |
| **Metadata Registry** | PostgreSQL | File/DB ownership tracking |

### MCP Configuration Storage
| Type | Location | Purpose |
|------|----------|---------|
| **Admin MCP** | `data/admins/mcp.json` | Admin-supplied MCP servers (applies globally) |

### Supporting Libraries
- **Job Scheduling**: APScheduler v3.10.0+
- **Task Queue**: temporalio v1.21.1+ (optional)
- **OCR**: Surya-OCR / PaddleOCR (optional, Linux x86_64)
- **Data Processing**: Pandas v2.2.0+, PyArrow
- **HTTP Client**: httpx
- **Logging**: loguru
- **Configuration**: Pydantic v2.12.5+, PyYAML

### Development Tools
- **Testing**: pytest v9.0.2+, pytest-asyncio
- **Package Management**: uv (Python 3.11+)
- **Containerization**: Docker, docker-compose

---

## Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         Channels Layer                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   TelegramChannel      ‚îÇ         HttpChannel                    ‚îÇ
‚îÇ  (python-telegram-bot)‚îÇ       (FastAPI + SSE)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ                               ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ   Middleware Stack    ‚îÇ
                ‚îÇ ‚Ä¢ Summarization      ‚îÇ
                ‚îÇ ‚Ä¢ Call Limits        ‚îÇ
                ‚îÇ ‚Ä¢ Retry Logic        ‚îÇ
                ‚îÇ ‚Ä¢ Todo Tracking      ‚îÇ
                ‚îÇ ‚Ä¢ Status Updates     ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ   LangGraph ReAct      ‚îÇ
                ‚îÇ   Agent Graph          ‚îÇ
                ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
                ‚îÇ ‚îÇ    call_model      ‚îÇ ‚îÇ
                ‚îÇ ‚îÇ    (LLM Reasoning) ‚îÇ ‚îÇ
                ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
                ‚îÇ           ‚îÇ             ‚îÇ
                ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
                ‚îÇ ‚îÇ   call_tools      ‚îÇ ‚îÇ
                ‚îÇ ‚îÇ (Tool Execution)  ‚îÇ ‚îÇ
                ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ                 ‚îÇ                  ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   File    ‚îÇ   ‚îÇ Database    ‚îÇ   ‚îÇ   Vector    ‚îÇ
    ‚îÇ  Sandbox  ‚îÇ   ‚îÇ  Tools      ‚îÇ   ‚îÇ   Store     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                 ‚îÇ                  ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ   Storage Backends     ‚îÇ
                ‚îÇ ‚Ä¢ File System         ‚îÇ
                ‚îÇ ‚Ä¢ SQLite             ‚îÇ
                ‚îÇ ‚Ä¢ LanceDB             ‚îÇ
                ‚îÇ ‚Ä¢ PostgreSQL          ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### ReAct Agent Flow

The agent follows the **ReAct (Reasoning + Acting)** pattern:

1. **Reason**: LLM analyzes user request and decides on actions
2. **Act**: Execute tools (file operations, database queries, web search, etc.)
3. **Observe**: Process tool results and update context
4. **Loop**: Repeat until task complete or iteration limit reached

**State Transition:**
```
[Start] ‚Üí [call_model] ‚Üí [has tool_calls?] ‚îÄ‚îÄ‚îÄ‚îÄNo‚îÄ‚îÄ‚Üí [END]
                    ‚îÇ                             Yes
                    ‚Üì
               [call_tools] ‚Üí [increment_iterations]
                    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí [call_model]
```

---

## Code Structure

```
executive_assistant/
‚îú‚îÄ‚îÄ src/executive_assistant/                    # Main application package
‚îÇ   ‚îú‚îÄ‚îÄ agent/                     # Agent logic & graph
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph.py              # LangGraph StateGraph definition
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nodes.py              # ReAct nodes: call_model, call_tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py              # AgentState TypedDict
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts.py            # System prompts for reasoning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ langchain_agent.py    # LangChain agent runtime
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ status_middleware.py   # Real-time progress tracking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware_debug.py    # Debug middleware
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ todo_display.py       # Todo list display logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ topic_classifier.py   # Message classification
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.py             # Conditional edge routing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ checkpoint_utils.py   # Checkpoint management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ langchain_state.py    # LangChain state wrapper
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ channels/                  # Communication channels
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py              # Abstract BaseChannel class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ telegram.py          # Telegram bot implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ http.py              # FastAPI HTTP channel
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ management_commands.py # CLI commands (/mem, /vdb, /tdb, /file)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ storage/                   # Data persistence layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ checkpoint.py        # LangGraph PostgreSQL checkpointer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_sandbox.py      # Secure file operations (thread-scoped)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db_storage.py        # Legacy DuckDB TDB storage (deprecated)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tdb_tools.py         # SQLite TDB tool implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sqlite_db_storage.py # SQLite backend (context + shared)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vdb_tools.py         # Vector database tool implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lancedb_storage.py   # LanceDB vector database backend
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user_registry.py     # Conversation logs & ownership tracking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ meta_registry.py     # Metadata/ownership tracking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reminder.py          # Reminder scheduling
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scheduled_flows.py    # APScheduler integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunking.py         # Document chunking for vector database
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mem_storage.py      # Embedded memory storage
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ workers.py          # Async worker pool
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ tools/                    # LangChain tool implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ registry.py          # Tool registry (get_all_tools)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ python_tool.py       # Python code execution (sandboxed)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ time_tool.py        # Timezone-aware time queries
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reminder_tools.py   # Reminder CRUD operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_tool.py      # Web search (SearXNG)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ocr_tool.py        # OCR image/PDF text extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ firecrawl_tool.py   # Firecrawl web scraping
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mem_tools.py       # Memory extraction tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ meta_tools.py      # System metadata queries
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ confirmation_tool.py # Large operation confirmation
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ skills/                   # Dynamic skill loading system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ registry.py         # Skill registry
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py           # Skill loader
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ builder.py          # Skill graph builder
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tool.py             # Skill tool wrapper
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ content/            # Skill definitions directory
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ config/                   # Configuration management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings.py         # Pydantic Settings class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_factory.py      # LLM model factory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py           # Config loader
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ constants.py        # Application constants
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                    # Utility functions
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ scheduler.py             # APScheduler integration
‚îÇ   ‚îú‚îÄ‚îÄ logging.py               # Loguru logging configuration
‚îÇ   ‚îú‚îÄ‚îÄ dev_server.py            # LangGraph dev server entry point
‚îÇ   ‚îî‚îÄ‚îÄ src/executive_assistant/main.py   # Application entry point
‚îÇ
‚îú‚îÄ‚îÄ tests/                        # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ test_agent.py            # Agent integration tests
‚îÇ   ‚îú‚îÄ‚îÄ test_file_sandbox.py     # File sandbox tests
‚îÇ   ‚îú‚îÄ‚îÄ test_db_storage.py       # DuckDB storage tests (legacy)
‚îÇ   ‚îú‚îÄ‚îÄ test_lancedb_vdb.py      # Vector database tests
‚îÇ   ‚îú‚îÄ‚îÄ test_python_tool.py      # Python execution tests
‚îÇ   ‚îú‚îÄ‚îÄ test_status_middleware.py # Middleware tests
‚îÇ   ‚îú‚îÄ‚îÄ test_scheduled_flows.py   # Scheduler tests
‚îÇ   ‚îú‚îÄ‚îÄ test_temporal_api.py     # Temporal integration tests
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py             # Pytest fixtures
‚îÇ
‚îú‚îÄ‚îÄ docker/migrations/            # PostgreSQL schema migrations
‚îÇ   ‚îî‚îÄ‚îÄ 000_init.sql             # Initial tables (thread-only)
‚îÇ
‚îú‚îÄ‚îÄ scripts/                      # Utility scripts
‚îÇ   ‚îî‚îÄ‚îÄ benchmark_results/        # Performance benchmark results
‚îÇ
‚îú‚îÄ‚îÄ docs/                         # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ kb/                      # Knowledge base docs
‚îÇ   ‚îú‚îÄ‚îÄ langchain-skills/        # LangChain skills documentation
‚îÇ   ‚îî‚îÄ‚îÄ ollama/                  # Ollama configuration
‚îÇ
‚îú‚îÄ‚îÄ data/                         # Application data
‚îÇ   ‚îú‚îÄ‚îÄ shared/                  # Organization-wide storage
‚îÇ   ‚îî‚îÄ‚îÄ users/                   # Thread-scoped storage
‚îÇ       ‚îî‚îÄ‚îÄ {thread_id}/
‚îÇ           ‚îú‚îÄ‚îÄ files/
‚îÇ           ‚îú‚îÄ‚îÄ tdb/
‚îÇ           ‚îú‚îÄ‚îÄ vdb/
‚îÇ           ‚îî‚îÄ‚îÄ mem/
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml                # Project dependencies & scripts
‚îú‚îÄ‚îÄ docker/config.yaml                   # Default configuration
‚îú‚îÄ‚îÄ docker/.env.example                  # Environment template
‚îú‚îÄ‚îÄ docker/Dockerfile                    # Container definition
‚îú‚îÄ‚îÄ docker/docker-compose.yml            # Development stack
‚îú‚îÄ‚îÄ langgraph.json                # LangGraph CLI configuration
‚îú‚îÄ‚îÄ README.md                     # User documentation
‚îú‚îÄ‚îÄ TODO.md                       # Development roadmap
‚îî‚îÄ‚îÄ CLAUDE.md                    # Development workflow notes
```

---

## Core Components

### 1. Agent Layer (`src/executive_assistant/agent/`)

**Purpose:** Implements the ReAct reasoning loop and manages agent state.

**Key Files:**
- `graph.py`: Defines LangGraph StateGraph with ReAct nodes
- `nodes.py`: Core node implementations
  - `call_model()`: Invokes LLM with conversation history
  - `call_tools()`: Executes LangChain tools
  - `increment_iterations()`: Tracks reasoning cycles
- `state.py`: AgentState TypedDict containing:
  - `messages`: Conversation history (with `add_messages` reducer)
  - `iterations`: Loop counter (prevents infinite loops)
  - `user_id`: Thread identifier (channel + channel user id)
  - `channel`: Source channel (telegram/http)
  - `structured_summary`: Topic-based conversation summary
  - `todos`: Task tracking list
- `prompts.py`: System prompts for LLM reasoning
- `langchain_agent.py`: LangChain agent runtime builder with middleware stack
- `status_middleware.py`: Real-time progress tracking with millisecond timing
- `todo_display.py`: Todo list display formatting
- `token_callbacks.py`: Token usage tracking (experimental, unused)

**Middleware Stack (via LangChain):**
1. **StatusUpdateMiddleware**: Real-time progress tracking with emoji indicators (ü§î Thinking, üõ†Ô∏è Tool N:, ‚úÖ Done)
2. **ThreadContextMiddleware**: Ensures thread_id ContextVar propagates to tool execution
3. **TodoListMiddleware**: Tracks planned tasks for multi-step operations
4. **TodoListDisplayMiddleware**: Displays planned tasks during execution (if channel enabled)
5. **SummarizationMiddleware**: Token-based conversation summarization (trigger: 5,000 / target: 1,000)
6. **ContextEditingMiddleware**: Edits context by clearing old tool uses (disabled by default)
7. **ModelCallLimitMiddleware**: Max 50 LLM calls per message (prevents infinite loops)
8. **ToolCallLimitMiddleware**: Max 100 tool calls per message (prevents runaway execution)
9. **ToolRetryMiddleware**: Automatic retry on tool failures with exponential backoff
10. **ModelRetryMiddleware**: Automatic retry on model failures with exponential backoff

**ThreadContextMiddleware (Custom):**
- **Purpose**: Fix Python ContextVar not propagating across LangGraph async task boundaries
- **Implementation**: Wraps tool execution via `awrap_tool_call()`
- **Functionality**:
  - Captures current `thread_id` from ContextVar before tool call
  - Restores `thread_id` immediately before tool execution
  - Logs all tool errors with full traceback at DEBUG level
- **Critical for**: FileSandbox, TDB, VDB, and all thread-scoped storage operations

### 2. Channels Layer (`src/executive_assistant/channels/`)

**Purpose:** Handles communication between users and agent across different platforms.

#### BaseChannel (`base.py`)
Abstract base class defining channel interface:
- `start()`: Initialize channel (connect to platform)
- `stop()`: Graceful shutdown
- `send_message()`: Send response to user
- `update_status()`: Update in-progress status
- `display_todos()`: Show todo list

#### TelegramChannel (`telegram.py`)
- Uses `python-telegram-bot` v22.5+
- Bot Commands: `/start`, `/reset`, `/remember`, `/debug`, `/mem`, `/reminder`, `/vdb`, `/tdb`, `/file`, `/meta`, `/user`
- Features:
  - Inline message editing for status updates (clean UI)
  - Debug mode toggle for verbose timing information
  - Per-thread asyncio locks to prevent message interleaving
  - Message queuing with deduplication
- Thread ID: Uses Telegram `chat_id` as `thread_id`
- Thread-only context (no group support)

#### HttpChannel (`http.py`)
- Built with FastAPI v0.115.0+
- Endpoints:
  - `POST /message`: Send message (supports SSE streaming with `stream: true`)
  - `GET /conversations/{id}`: Get conversation history
  - `GET /health`: Health check
- Features:
  - Server-sent events (SSE) for real-time streaming
  - JSON request/response models (Pydantic)
  - **Open access** - authentication handled by frontend application
  - **Non-streaming endpoint** - collects all messages and returns as JSON array
- Thread ID: Format `http:{conversation_id}`
- Authorization: Bypasses allowlist (frontend auth pattern)

### 3. Storage Layer (`src/executive_assistant/storage/`)

**Purpose:** Provides thread-scoped, privacy-first data storage with multi-tenancy support.

#### Storage Hierarchy

```
data/
‚îú‚îÄ‚îÄ admins/           # admin-managed configuration and allowlist
‚îÇ   ‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompt.md
‚îÇ   ‚îú‚îÄ‚îÄ skills/
‚îÇ   ‚îú‚îÄ‚îÄ mcp.json
‚îÇ   ‚îî‚îÄ‚îÄ user_allowlist.json
‚îú‚îÄ‚îÄ shared/           # scope="shared" (organization-wide)
‚îÇ   ‚îú‚îÄ‚îÄ files/
‚îÇ   ‚îú‚îÄ‚îÄ tdb/
‚îÇ   ‚îî‚îÄ‚îÄ vdb/
‚îî‚îÄ‚îÄ users/            # scope="context" (thread-only)
    ‚îî‚îÄ‚îÄ {thread_id}/
        ‚îú‚îÄ‚îÄ files/
        ‚îú‚îÄ‚îÄ tdb/
        ‚îú‚îÄ‚îÄ vdb/
        ‚îî‚îÄ‚îÄ mem/
```

#### Key Storage Components

**FileSandbox (`file_sandbox.py`)**
- **Purpose**: Secure file operations with thread isolation
- **Isolation**: Uses Python `ContextVar` for thread-scoped paths
- **Features**:
  - Path traversal protection (prevents `../../../` attacks)
  - File size limits (configurable via `MAX_FILE_SIZE_MB`)
  - File extension whitelisting
  - Ownership tracking in PostgreSQL
- **Tools**:
  - `read_file`, `write_file`: Text file I/O
  - `create_folder`, `delete_folder`, `rename_folder`: Directory management
  - `move_file`: File relocation
  - `glob_files`: Pattern matching (`*.py`, `**/*.json`)
  - `grep_files`: Regex content search

**TDBStorage (`sqlite_db_storage.py`, `tdb_tools.py`)**
- **Backend**: SQLite (context + shared)
- **Purpose**: Structured/tabular data storage
- **Use Cases**: Timesheets, logs, analysis datasets
- **Tools**:
  - `create_tdb_table`: Create from JSON/CSV with auto schema inference
  - `insert_tdb_table`, `query_tdb`: SQL operations
  - `list_tdb_tables`, `describe_tdb_table`: Schema inspection
  - `export_tdb_table`, `import_tdb_table`: Data portability (CSV, JSON, Parquet)
- **Legacy**: `db_storage.py` retains DuckDB utilities (deprecated)

**Vector Database (`lancedb_storage.py`, `vdb_tools.py`)**
- **Backend**: LanceDB with sentence-transformers embeddings
- **Model**: `all-MiniLM-L6-v2` (384 dimensions)
- **Purpose**: Long-term knowledge retrieval
- **Use Cases**: Meeting notes, decisions, documentation
- **Features**:
  - Semantic search (vector similarity)
  - Document chunking (configurable `chunk_size`)
  - Metadata filtering
- **Tools**:
  - `create_vdb_collection`: Create collection with embeddings
  - `add_vdb_documents`: Add documents (auto-chunking)
  - `search_vdb`: Semantic search
  - `vdb_list`, `drop_vdb_collection`: Collection management

**UserRegistry (`user_registry.py`)**
- **Purpose**: Conversation logs and ownership tracking
- **Features**:
  - Thread-scoped conversation history
  - Ownership tracking for files/TDB/VDB/reminders per thread
  - Message audit log for troubleshooting

**Checkpoint (`checkpoint.py`)**
- **Purpose**: LangGraph state persistence
- **Backend**: PostgreSQL (via `langgraph-checkpoint-postgres`)
- **Tables**:
  - `checkpoints`: State snapshots per thread
  - `checkpoint_blobs`: Large message payloads
- **Alternative**: In-memory for development

**MetaRegistry (`meta_registry.py`)**
- **Purpose**: Ownership tracking for audit and data migration
- **Tables**:
  - `file_paths`: File ownership per thread
  - `tdb_paths`: Transactional database ownership per thread
  - `vdb_paths`: Vector database ownership per thread
  - `adb_paths`: Analytics DB ownership per thread
- **Operations**: Track all create/delete operations

**User Allowlist (`user_allowlist.py`)**
- **Purpose**: Channel-based access control
- **Implementation**:
  - HTTP channels: **Always authorized** (authentication handled by frontend)
  - Telegram channels: **Require allowlist** (anyone can message the bot)
  - Admin thread IDs: Always authorized (from `docker/config.yaml`)
- **File**: `data/admins/user_allowlist.json`
- **Format**: `{"users": ["telegram:123456", "telegram:789012"]}`
- **Rationale**:
  - HTTP: Frontend application handles authentication (JWT sessions, OAuth, etc.)
  - Telegram: Public platform, need allowlist to prevent unauthorized access
- **Pattern**: Follows LangGraph Studio dev/up model - auth is frontend responsibility

**Reminder (`reminder.py`, `scheduled_flows.py`)**
- **Purpose**: Scheduled notification system
- **Backend**: APScheduler (in-memory) + PostgreSQL persistence
- **Features**:
  - One-time and recurring reminders
  - Recurrence rules (daily, weekly, custom)
  - Multi-thread triggering (notify across conversations)
  - Timezone-aware scheduling
- **Table**: `reminders`

### Analytics DB (DuckDB)

- Context-scoped DuckDB for analytics queries.
- Stored at `data/users/{thread_id}/analytics/duckdb.db`.
- Tool: `query_adb` (read/write SQL for analysis).

### 4. Tools Layer (`src/executive_assistant/tools/`)

**Purpose:** LangChain tool implementations that the agent can invoke.

**Tool Registry (`registry.py`)**
- `get_all_tools()`: Aggregates all tool categories (83 total tools)
- **All tools available by default** - No progressive disclosure filtering
  - Token overhead: ~937 tokens (0.5% of 200K context)
  - Prevents multi-step workflow breakage
  - Removed: `get_tools_for_request()` (deprecated, caused tool loss mid-conversation)
- Categories:
  - File tools (11 tools): File operations
  - TDB tools (10 tools): Database operations
  - ADB tools (5 tools): Analytics database operations
  - VDB tools (7 tools): Vector database operations
  - Time tools (3 tools): Timezone queries
  - Reminder tools (4 tools): Reminder management
  - Python tools (2 tools): Code execution
  - Search tools (2 tools): Web search via SearXNG
  - Browser tools (1 tool): Playwright scraping
  - OCR tools (2 tools): Image/PDF text extraction
  - Firecrawl tools (3 tools): Web scraping
  - Agent tools (6 tools): Mini-agent creation and management
  - Flow tools (5 tools): Workflow automation
  - Memory tools (6 tools): Memory extraction and search
  - Meta tools (3 tools): System metadata
  - MCP tools: Configurable MCP server integration
  - Confirmation tool (1 tool): Large operation confirmation
  - Skills tool (1 tool): Dynamic skill loading

**Python Tool (`python_tool.py`)**
- **Purpose**: Safe Python code execution for data processing
- **Security**:
  - 30-second timeout
  - Thread-scoped I/O (via `file_sandbox` paths)
  - Whitelisted modules: `json`, `csv`, `math`, `datetime`, `random`, `statistics`, `urllib`, `pandas`, `numpy`
  - Path traversal protection
- **Tools**:
  - `python_exec`: Execute Python code
  - `python_exec_file`: Execute Python file

**Time Tool (`time_tool.py`)**
- **Purpose**: Timezone-aware time queries
- **Tools**:
  - `get_current_time(timezone)`: Get time in specific timezone
  - `get_current_date(timezone)`: Get date in specific timezone
  - `list_timezones()`: List available timezones

**Search Tool (`search_tool.py`)**
- **Purpose**: Web search via SearXNG
- **Features**: Privacy-focused search aggregation
- **Config**: `SEARXNG_HOST` environment variable

**OCR Tool (`ocr_tool.py`)**
- **Purpose**: Extract text from images and PDFs
- **Engines**: Surya-OCR (default) or PaddleOCR (Linux x86_64 only)
- **Features**:
  - PDF text extraction (multi-page)
  - Image OCR (PNG, JPG, etc.)
  - Structured extraction with LLM (JSON output)
- **Config**: `ocr` section in `docker/config.yaml`

### 5. Skills System (`src/executive_assistant/skills/`)

**Purpose:** Progressive disclosure of advanced patterns through dynamic skill loading.

**Components:**
- `registry.py`: Skill registration
- `loader.py`: Load skill definitions from `.skill` files
- `builder.py`: Build LangGraph graphs from skills
- `tool.py`: Wrap skills as LangChain tools
- `content/`: Skill definition files

**Example Skill:** `react-agent.skill` (17KB)
- Defines ReAct agent pattern as a reusable skill
- Can be loaded via `load_skill` tool

### 6. Configuration Layer (`src/executive_assistant/config/`)

**Purpose:** Centralized configuration management.

**Components:**
- `settings.py`: Pydantic Settings class (environment + YAML)
- `llm_factory.py`: LLM model creation (provider-agnostic)
- `loader.py`: Load config from `docker/config.yaml` and `docker/.env`
- `constants.py`: Application constants

**Configuration Sources** (priority order):
1. Environment variables (`docker/.env`)
2. `docker/config.yaml` (application defaults)
3. Pydantic defaults

**Key Settings:**
- `DEFAULT_LLM_PROVIDER`: LLM provider selection (anthropic, openai, zhipu, ollama)
- `CHECKPOINT_STORAGE`: postgres or memory
- `EXECUTIVE_ASSISTANT_CHANNELS`: Comma-separated list (telegram, http)
- `MAX_ITERATIONS`: Max ReAct loops (default: 20)
- Middleware thresholds (max_tokens, call limits, etc.)

### 7. Workflows Layer (`src/executive_assistant/workflows/`)

**Purpose:** Integration with external workflow engines (currently Temporal).

**Components:**
- `health.py`: Health check workflow
- `temporal_client.py`: Temporal client wrapper

**Usage:** Optional integration for long-running, durable workflows.

### 8. Scheduler (`scheduler.py`)

**Purpose:** APScheduler integration for reminder notifications.

**Features:**
- Async job scheduling
- Job persistence (optional)
- Graceful shutdown

---

## Data Flow

### Message Processing Flow

```
[User Message]
    ‚îÇ
    ‚Üì
[Channel Layer]  (TelegramChannel or HttpChannel)
    ‚îÇ  ‚Ä¢ Normalize message to HumanMessage
    ‚îÇ  ‚Ä¢ Set thread_id in ContextVars
    ‚îÇ  ‚Ä¢ Acquire thread lock (prevent concurrent processing)
    ‚îÇ
    ‚Üì
[Middleware Stack] (LangChain)
    ‚îÇ  ‚Ä¢ Summarization (if token limit exceeded)
    ‚îÇ  ‚Ä¢ Call limits (check max calls per message)
    ‚îÇ  ‚Ä¢ Status updates (enable streaming)
    ‚îÇ  ‚Ä¢ Todo tracking
    ‚îÇ
    ‚Üì
[LangGraph ReAct Agent]
    ‚îÇ
    ‚îú‚îÄ‚Üí [call_model Node]
    ‚îÇ      ‚Ä¢ Load conversation history from state
    ‚îÇ      ‚Ä¢ Invoke LLM with system prompt + messages
    ‚îÇ      ‚Ä¢ Record timing (milliseconds)
    ‚îÇ      ‚Ä¢ Check for tool_calls
    ‚îÇ
    ‚îú‚îÄ‚Üí [Route: Tools or End?]
    ‚îÇ      ‚Ä¢ If tool_calls: go to tools
    ‚îÇ
    ‚îú‚îÄ‚Üí [call_tools Node]
    ‚îÇ      ‚Ä¢ Execute tool functions
    ‚îÇ      ‚Ä¢ Each tool:
    ‚îÇ        ‚Ä¢ Read ContextVars (thread_id)
    ‚îÇ        ‚Ä¢ Access storage (file, TDB, VDB)
    ‚îÇ        ‚Ä¢ Return results
    ‚îÇ
    ‚îú‚îÄ‚Üí [increment_iterations Node]
    ‚îÇ      ‚Ä¢ iterations += 1
    ‚îÇ
    ‚îî‚îÄ‚Üí [Loop back to call_model] or [END]
         ‚îÇ
         ‚Üì
[Middleware Stack]
    ‚îÇ  ‚Ä¢ Final status update
    ‚îÇ  ‚Ä¢ Call limit logging
    ‚îÇ
    ‚Üì
[Channel Layer]
    ‚îÇ  ‚Ä¢ Stream AIMessage chunks (if streaming)
    ‚îÇ  ‚Ä¢ Or send complete response
    ‚îÇ  ‚Ä¢ Edit status message (if enabled)
    ‚îÇ
    ‚Üì
[Checkpoint Saver] (PostgreSQL)
    ‚îÇ  ‚Ä¢ Save final state to checkpoints table
    ‚îÇ  ‚Ä¢ Async write (non-blocking)
    ‚îÇ
    ‚Üì
[User receives response]
```

### Tool Execution Flow

```
[Agent calls tool]
    ‚îÇ
    ‚Üì
[ThreadContextMiddleware.awrap_tool_call()]
    ‚îÇ  ‚Ä¢ Capture thread_id from ContextVar
    ‚îÇ  ‚Ä¢ Set thread_id again (ensure propagation)
    ‚îÇ  ‚Ä¢ Log any errors with full traceback
    ‚îÇ
    ‚Üì
[Tool function executes]
    ‚îÇ
    ‚îú‚îÄ‚Üí Read ContextVars (_thread_id) ‚úì (now works!)
    ‚îÇ
    ‚îú‚îÄ‚Üí Build scoped path:
    ‚îÇ      ‚Ä¢ if scope="shared" ‚Üí data/shared/
    ‚îÇ      ‚Ä¢ if scope="context" ‚Üí data/users/{thread_id}/
    ‚îÇ
    ‚îú‚îÄ‚Üí Check permissions:
    ‚îÇ      ‚Ä¢ FileSandbox: path traversal protection
    ‚îÇ      ‚Ä¢ MetaRegistry: ownership verification
    ‚îÇ
    ‚îú‚îÄ‚Üí Access storage backend:
    ‚îÇ      ‚Ä¢ File: Local filesystem
    ‚îÇ      ‚Ä¢ TDB: SQLite (context + shared)
    ‚îÇ      ‚Ä¢ VDB: LanceDB (collection-scoped)
    ‚îÇ
    ‚îú‚îÄ‚Üí Record operation:
    ‚îÇ      ‚Ä¢ MetaRegistry: Update ownership tracking
    ‚îÇ      ‚Ä¢ UserRegistry: Update audit log
    ‚îÇ
    ‚îî‚îÄ‚Üí Return results to agent
```

---

## Storage Architecture

### PostgreSQL Schema

| Table | Purpose | Key Columns |
|-------|---------|-------------|
| `checkpoints` | LangGraph state snapshots | `thread_id`, `checkpoint_ns`, `checkpoint_id` |
| `checkpoint_blobs` | Large message payloads | `thread_id`, `checkpoint_id`, `blob` |
| `conversations` | Conversation metadata | `thread_id`, `created_at` |
| `messages` | Message audit log | `thread_id`, `message_id`, `role`, `content` |
| `file_paths` | File ownership tracking | `thread_id`, `path`, `created_at` |
| `tdb_paths` | TDB ownership tracking | `thread_id`, `tdb_path`, `created_at` |
| `vdb_paths` | VDB ownership tracking | `thread_id`, `vdb_path`, `created_at` |
| `adb_paths` | Analytics DB ownership tracking | `thread_id`, `adb_path`, `created_at` |
| `reminders` | Scheduled reminders | `reminder_id`, `thread_id`, `trigger_time`, `recurrence` |

### Data Isolation Model

**Thread-Level Isolation (Default)**
- Each conversation gets unique `thread_id` (e.g., Telegram chat_id)
- Data stored under `data/users/{thread_id}/`
- Prevents cross-thread data leakage

**Organization-Level Sharing**
- Admins can write to `data/shared/`
- All users can read from shared storage
- Use cases: Company-wide knowledge, templates
 
Thread-only context
- Enables multi-thread access to user data

### Vector Database Architecture

**LanceDB Collections**
- Per-thread collections
- Embeddings via sentence-transformers
- Metadata filtering support

**Document Chunking**
- Split documents into ~3000 character chunks
- Overlap for context preservation
- Configurable via `vector_store.chunk_size`

**Search Options**
1. **Semantic Search**: Vector similarity (cosine distance)
2. **Full-Text Search**: Keyword matching
3. **Hybrid Search**: Combined score

---

## Key Libraries & Frameworks

### LangGraph (`langgraph >= 1.0.6`)
**Role:** Agent orchestration and state management
**Key Features Used:**
- `StateGraph`: Build custom agent graphs
- `add_messages` reducer: Automatic message history accumulation
- `BaseCheckpointSaver`: State persistence interface
- `RunnableConfig`: Per-invocation configuration

**Key Components:**
```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.postgres import PostgresSaver
```

### LangChain (`langchain >= 0.3.27`)
**Role:** Unified LLM and tool interface
**Key Features Used:**
- `BaseChatModel`: Provider-agnostic LLM interface
- `BaseTool`: Tool implementation base class
- Middleware stack: Summarization, retry, limits
- `StructuredTool`: Tools with JSON schemas

**Key Components:**
```python
from langchain_core.language_models import BaseChatModel
from langchain_core.tools import BaseTool, tool
from langchain.agents.middleware import (
    SummarizationMiddleware,
    CallLimitMiddleware,
    TodoListMiddleware,
)
```

### LLM Providers

**Anthropic (`langchain-anthropic >= 0.3.22`)**
- Claude models (Haiku, Sonnet)
- Used by default in `docker/config.yaml`

**OpenAI (`langchain-openai >= 0.3.35`)**
- GPT models (GPT-4o, GPT-4o-mini)
- Alternative to Anthropic

**Zhipu AI (`zhipuai`)**
- GLM-4 models
- Chinese LLM provider

**Ollama (`langchain-ollama >= 0.3.1`)**
- Local models or Ollama Cloud
- Privacy-focused option

### FastAPI (`fastapi >= 0.115.0`)
**Role:** HTTP channel implementation
**Key Features Used:**
- ASGI async server
- Pydantic models for validation
- Server-Sent Events (SSE) streaming
- CORS support

**Key Components:**
```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
```

### APScheduler (`apscheduler >= 3.10.0`)
**Role:** Reminder scheduling
**Key Features Used:**
- Async job scheduling
- Cron-like recurrence rules
- Timezone-aware triggers

**Key Components:**
```python
from apscheduler.schedulers.asyncio import AsyncIOScheduler
```

### DuckDB (`duckdb >= 1.1.0`) (legacy)
**Role:** Thread-scoped database
**Key Features Used:**
- Embedded, no external process needed
- SQL compatibility
- Fast in-memory queries
- CSV/JSON/Parquet import/export

### LanceDB (`lancedb >= 0.15.0`)
**Role:** Vector store for semantic search
**Key Features Used:**
- Embedded vector database
- Sentence-transformers integration
- Hybrid search (vector + full-text)
- Metadata filtering

### psycopg + asyncpg (`asyncpg >= 0.30.0`)
**Role:** PostgreSQL async driver
**Key Features Used:**
- Async connection pooling
- Prepared statements
- Type safety

### Pydantic (`pydantic >= 2.12.5`)
**Role:** Configuration and validation
**Key Features Used:**
- `BaseSettings`: Environment variable management
- Type validation
- YAML configuration loading

**Key Components:**
```python
from pydantic import BaseModel, Field, BaseSettings
from pydantic_settings import BaseSettings
```

### Loguru (`loguru >= 0.7.2`)
**Role:** Structured logging
**Key Features Used:**
- JSON logging
- Log rotation
- Millisecond timestamps
- Context-aware logging

### Python Standard Library
- `asyncio`: Async runtime
- `pathlib`: Path manipulation
- `contextvars`: Thread-scoped context
- `datetime`, `timezone`: Time handling

---

## Configuration Management

### Configuration Files

**`docker/config.yaml`** - Application Defaults
- LLM provider settings
- Storage paths
- Agent parameters
- Middleware thresholds
- Vector store settings
- OCR configuration

**`docker/.env`** - Environment-Specific Overrides
- API keys (secrets)
- Channel configuration
- Database credentials
- External service URLs

**Admin Customization (`data/admins/`)**
- `prompts/prompt.md`: Prepended before the system prompt (admin-only).
- `skills/`: Loaded as additional skills at startup (admin-only).
- `mcp.json`: Loaded when MCP adapters are available (admin-only).
- `user_allowlist.json`: Access control list managed by admins.

**`pyproject.toml`** - Project Metadata
- Dependencies
- Build configuration
- Scripts (`executive_assistant`, `executive_assistant-dev`)

### Configuration Loading

1. **Load `docker/config.yaml`** ‚Üí `Settings` object
2. **Override with `docker/.env`** ‚Üí Environment variables
3. **Validate with Pydantic** ‚Üí Type checking
4. **Use in application** ‚Üí `settings` singleton

**Example:**
```python
from executive_assistant.config import settings

# Access settings
provider = settings.DEFAULT_LLM_PROVIDER
max_iter = settings.MAX_ITERATIONS
```

### LLM Factory

**`llm_factory.py`** creates provider-agnostic models:
```python
from executive_assistant.config import create_model

# Creates model based on DEFAULT_LLM_PROVIDER
model = create_model()  # Returns BaseChatModel
```

**Supported Providers:**
- `anthropic`: Claude models
- `openai`: GPT models
- `zhipu`: GLM-4 models
- `ollama`: Local/Cloud models

---

## Token Usage Tracking

Executive Assistant monitors token consumption to control costs and understand usage patterns:

### Implementation

**HTTP Channel Token Tracking** (`channels/http.py`):
- Extracts `usage_metadata` from AIMessage objects in the event stream
- Logs input/output/total tokens per conversation: `tokens={input}+{output}={total}`
- **Provider Support**:
  - ‚úÖ OpenAI: Full token tracking (input + output + total)
  - ‚úÖ Anthropic: Full token tracking
  - ‚ùå Ollama: No metadata provided (usage not tracked)

### Token Breakdown

Typical token usage for a conversation:

| Component | Token Count | Notes |
|-----------|-------------|-------|
| System prompt | ~50 tokens | "You are Jen, a personal AI assistant..." |
| Tools (71 tools) | ~7,500 tokens | Tool names, descriptions, JSON schemas |
| Conversation messages | Variable | Grows with each turn (¬±30-80 tokens per round) |
| **Total (Round 1)** | ~7,550 tokens | System + tools + first user message |
| **Total (Round 5)** | ~8,000 tokens | +450 tokens from 4 conversation turns |

### Example Log Output

```bash
CH=http CONV=http_user123 TYPE=token_usage | message tokens=7581+19=7600
CH=http CONV=http_user123 TYPE=token_usage | message tokens=7900+808=8708
CH=http CONV=http_user123 TYPE=token_usage | message tokens=8726+803=9529
```

**Interpretation**:
- Input tokens grow as conversation context is preserved
- Output tokens vary based on response complexity
- Cache hits (OpenAI) reduce effective token cost significantly

### Summarization Middleware

**Configuration** (`docker/config.yaml`):
```yaml
middleware:
  summarization:
    enabled: true
    max_tokens: 5000     # Trigger: 5,000 conversation messages
    target_tokens: 1000  # Target: 1,000 messages after summarization
```

**Important Notes**:
- Threshold applies to **conversation messages only**, not total LLM input
- Does NOT count the ~7,500 token system prompt + tools overhead
- With 128K context window (GPT-OSS 20B), 5,000 messages is very conservative
- Summarization calls the LLM to compress older messages into a summary

**When to Adjust**:
- **Lower threshold** (500-1,000): For faster summarization, more aggressive compression
- **Higher threshold** (10,000+): For longer conversations before summarization
- **Use fractional triggering**: `trigger: 0.4` (40% of model context window)

---

## Deployment Architecture

### Docker Deployment

**`docker/Dockerfile`** - Multi-stage build
- Base: `python:3.13-slim`
- Dependencies: `uv sync --frozen`
- User: `executive_assistant` (non-root)
- Ports: 8000
- Volumes: `/app/data`

**`docker/docker-compose.yml`** - Development stack
```yaml
services:
  executive_assistant:    # Agent application
  postgres:  # PostgreSQL for state persistence
```

### Production Deployment

**Environment Variables Required:**
```bash
# LLM Provider
DEFAULT_LLM_PROVIDER=anthropic  # or openai, zhipu, ollama
ANTHROPIC_API_KEY=sk-ant-xxx

# Channels
EXECUTIVE_ASSISTANT_CHANNELS=telegram,http

# Telegram
TELEGRAM_BOT_TOKEN=your-bot-token

# PostgreSQL
POSTGRES_HOST=postgres
POSTGRES_PASSWORD=executive_assistant_password

# Optional: External Services
SEARXNG_HOST=https://your-searxng.com
FIRECRAWL_API_KEY=fc-xxx
```

### Development Workflow

**Local Testing (Recommended):**
```bash
# Start PostgreSQL
docker compose up -d postgres

# Run locally (no Docker rebuild needed)
uv run executive_assistant

# Run HTTP only
EXECUTIVE_ASSISTANT_CHANNELS=http uv run executive_assistant
```

**Docker Deployment:**
```bash
# Build and run all services
docker compose up -d

# Rebuild executive_assistant container
docker compose build --no-cache executive_assistant
```

### Scaling Considerations

**Stateless Channels:**
- HTTP channel can scale horizontally (multiple instances)
- Load balancer distributes traffic

**Stateful Agent:**
- PostgreSQL checkpointing enables persistence
- Multiple instances share state via PostgreSQL

**Storage:**
- File storage: Use networked volume (NFS, S3, etc.)
- Vector store: LanceDB embedded (one instance per agent)

---

## Testing Strategy

### Test Framework
- **pytest v9.0.2+**: Test runner
- **pytest-asyncio v1.3.0+**: Async test support
- **pytest-recording**: HTTP request recording/replay

### Test Categories

**Unit Tests**
- `test_file_sandbox.py`: File operations
- `test_db_storage.py`: DuckDB operations (legacy)
- `test_lancedb_vdb.py`: Vector database operations
- `test_python_tool.py`: Python execution

**Integration Tests**
- `test_agent.py`: Agent execution with mock LLM
- `test_status_middleware.py`: Middleware behavior
- `test_temporal_api.py`: Temporal integration

**System Tests**
- `test_integration_pg.py`: Full PostgreSQL integration
- `test_scheduled_flows.py`: Reminder scheduling

### Test Fixtures (`conftest.py`)
- Mock LLM responses
- Test data generation
- Async event loop management

### VCR Cassettes
- Record live LLM calls for replay in tests
- Avoid hitting rate limits
- Enable deterministic tests

**Recording:**
```bash
RUN_LIVE_LLM_TESTS=1 uv run pytest -m "langchain_integration and vcr" --record-mode=once
```

---

## Appendix: Key Concepts

### ReAct Pattern
The agent follows the **ReAct** (Reasoning + Acting) pattern:
1. **Reason**: LLM analyzes request and decides what to do
2. **Act**: Execute tools to gather information or perform actions
3. **Observe**: Process results and update context
4. **Loop**: Repeat until task complete

### Context Variables
Python `ContextVar` provides thread-scoped context:
```python
_thread_id: ContextVar[str] = ContextVar("_thread_id", default=None)
```

This ensures:
- Thread isolation (no cross-thread data leakage)
- Async propagation (works with asyncio)
- Zero performance overhead

### Middleware Chain
LangChain middleware wraps tool/model calls:
```
[User Request]
  ‚Üí [TodoListMiddleware] (track planned tasks)
  ‚Üí [SummarizationMiddleware] (reduce context if needed)
  ‚Üí [CallLimitMiddleware] (check call limits)
  ‚Üí [RetryMiddleware] (retry on failure)
  ‚Üí [Model/Tool]
  ‚Üí [StatusUpdateMiddleware] (stream progress)
  ‚Üí [TodoListDisplayMiddleware] (show todos)
  ‚Üí [User Response]
```

### Checkpointing
LangGraph saves state after each node execution:
- Resume from checkpoint after interruption
- Multi-session conversations
- Debug agent decisions

### Tool Selection
The LLM chooses tools dynamically based on:
- Request context
- Available tools
- Tool descriptions and schemas

This enables:
- Context-aware behavior
- Dynamic tool chains
- Multi-step reasoning

---

## Document Changelog

| Version | Date | Changes |
|---------|------|---------|
| 1.1.0 | 2026-01-28 | Added ThreadContextMiddleware, HTTP auth bypass, error logging enhancements |
| 1.0.0 | 2026-01-21 | Initial technical architecture documentation |

### Key Changes in v1.1.0

**Bug Fixes:**
- Fixed progressive disclosure bug causing tool loss mid-conversation
- Fixed thread_id ContextVar not propagating to tool execution
- Fixed HTTP channel non-streaming endpoint (missing `stream_agent_response` method)
- Enhanced error logging with full tracebacks at DEBUG level

**Architecture Improvements:**
- All 83 tools now available by default (~937 tokens = 0.5% of 200K context)
- HTTP channel bypasses allowlist (frontend authentication pattern)
- ThreadContextMiddleware ensures context propagation across async boundaries
- Removed deprecated `get_tools_for_request()` function

**New Components:**
- `src/executive_assistant/agent/thread_context_middleware.py` - Context propagation middleware
- Enhanced `is_authorized()` in `user_allowlist.py` - Channel-specific authorization

---

**Document Author:** Generated via analysis of Executive Assistant codebase
**Contact:** See repository for issues and contributions
