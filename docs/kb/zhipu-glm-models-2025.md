# Zhipu AI GLM Models Reference (2025)

**Last Updated:** 2025-01-19
**Provider:** Zhipu AI (Êô∫Ë∞±AI)
**Website:** https://open.bigmodel.cn/
**Pricing:** https://bigmodel.cn/pricing

---

## Model Overview

Zhipu AI (China) offers the GLM (General Language Model) series, with both open-source and API options. Known for strong performance in Chinese/English bilingual tasks and competitive pricing.

**üö¢ Latest:** GLM-4.7 released December 21-22, 2025 - Beats GPT-5.2 and Claude in several benchmarks!

---

## Available Models

### üåü GLM-4.7 (NEW - December 2025)

#### **Characteristics**
- **Type:** Open-Weight Next-Generation Model
- **Release:** December 21-22, 2025
- **Context Window:** 128K+ tokens
- **Strengths:**
  - **Beats GPT-5.2 and Claude models** in several benchmarks
  - 38% performance improvement over GLM-4.6
  - HLE Benchmark: 42.8% (Humanity's Last Exam)
  - Excellent at coding, reasoning, and agentic capabilities
  - Deep mathematical reasoning
  - Multi-file processing capabilities
  - Compatible with 20+ popular AI coding tools (including Claude Code)
  - Designed for real-world development workflows
  - Open-weight model (can self-host)
- **Pricing:**
  - Input: $0.60/1M tokens
  - Output: $2.20/1M tokens
  - Subscription: ¬•20/month with high quotas
- **Use Cases:**
  - **Coding assistance** (best-in-class performance)
  - Complex reasoning tasks
  - Long-document processing
  - Mathematical problem-solving
  - AI agents and tool-calling
  - Real-world development workflows
- **Trade-offs:**
  - Newer model (less battle-tested than GPT-4/Claude)
  - Chinese provider (potential latency outside Asia)
- **Why It Matters:**
  - First Chinese model to competitively beat GPT-5.2 and Claude
  - Very competitive pricing ($0.60/$2.20 vs GPT-4o's $2.50/$10.00)
  - Open-weight (can self-host)

---

### GLM-4.5

#### **Characteristics**
- **Type:** Open Source Large Model
- **Parameters:** 355B
- **Release:** 2025
- **Context Window:** 128K tokens
- **Strengths:**
  - Open source (can self-host)
  - Strong reasoning capabilities
  - Excellent coding performance
  - Designed for AI agents
  - Competitive with GPT-4 level performance
- **Use Cases:**
  - AI agent development
  - Complex reasoning tasks
  - Bilingual applications (Chinese/English)
  - Self-hosted deployment
- **Trade-offs:**
  - Very large model (requires significant compute)
  - Slower inference
  - Higher cost to self-host

### GLM-4.5-Air

#### **Characteristics**
- **Type:** Efficient Variant
- **Parameters:** ~100B (estimated)
- **Strengths:**
  - More efficient than GLM-4.5
  - Lower cost
  - Faster inference
  - Good balance of performance and cost
- **Use Cases:**
  - Production applications
  - Cost-sensitive projects
  - General purpose tasks
- **Trade-offs:**
  - Lower performance than full GLM-4.5

### GLM-4.6

#### **Characteristics**
- **Type:** Latest Coding Model
- **Release:** Late 2025
- **Strengths:**
  - Optimized for coding tasks
  - Native tool-calling support
  - Vision capabilities (GLM-4.6V)
  - Strong performance on coding benchmarks
- **Use Cases:**
  - Code generation
  - Code review
  - Technical tasks
  - Vision + coding tasks
- **Trade-offs:**
  - Newer model (less battle-tested)
  - Pricing may be premium

### GLM-4.6V-Flash

#### **Characteristics**
- **Type:** Fast Vision Model
- **Strengths:**
  - Vision capabilities
  - Fast inference
  - Lower cost
- **Use Cases:**
  - Image understanding
  - Multimodal tasks
  - Quick analysis

### GLM-4 Flash

#### **Characteristics**
- **Type:** Free Tier Model
- **Context Window:** 128K tokens
- **Strengths:**
  - **Free to use** (with rate limits)
  - Decent performance
  - Good for testing/development
- **Pricing:** **FREE**
- **Use Cases:**
  - Development and testing
  - Prototyping
  - Low-volume applications
  - Budget-constrained projects
- **Trade-offs:**
  - Rate limits apply
  - Lower performance than paid models
  - May have queue delays

### GLM-4 Plus

#### **Characteristics**
- **Type:** Premium Model
- **Strengths:**
  - Highest performance in GLM-4 series
  - Best quality outputs
  - Priority access
- **Use Cases:**
  - Production applications
  - Quality-critical tasks
- **Trade-offs:**
  - Higher cost
  - May not be cost-effective vs competitors

---

## Performance Comparison

| Model | Intelligence | Speed | Cost | Best For |
|-------|--------------|-------|------|----------|
| **GLM-4.7** ‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | $$ | **Coding, reasoning, beats GPT-5.2** |
| **GLM-4.6** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | $$$$ | Coding tasks |
| **GLM-4.5** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | $$$ | Complex tasks, AI agents |
| **GLM-4.5-Air** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | $$ | Balanced performance |
| **GLM-4 Plus** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | $$$$ | Premium quality |
| **GLM-4 Flash** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | FREE | Testing, low-volume |

**üåü GLM-4.7 is the new flagship model** - 38% better than GLM-4.6 and competitive with GPT-5.2/Claude.

---

## Pricing (CNY, Estimated)

| Model | Input (per 1M tokens) | Output (per 1M tokens) | USD Equivalent |
|-------|----------------------|----------------------|----------------|
| GLM-4 Flash | **FREE** | **FREE** | $0 |
| GLM-4.5-Air | ~¬•5 | ~¬•5 | ~$0.70 |
| **GLM-4.7** ‚≠ê | ~¬•4.3 | ~¬•15.7 | **$0.60 / $2.20** |
| GLM-4 Plus | ~¬•12 | ~¬•12 | ~$1.70 |
| GLM-4.6 | ~¬•20 | ~¬•20 | ~$2.80 |
| GLM-4.5 | Contact sales | Contact sales | - |

*Note: Pricing in CNY (Chinese Yuan). ¬•1 ‚âà $0.14 USD*

**üåü GLM-4.7 offers exceptional value** - Competitive with GPT-5.2 at 4√ó lower cost!

---

## Special Features

### GLM-Realtime
- Real-time voice interaction
- Low latency streaming
- Always-listening mode

### Multimodal Capabilities
- GLM-4.6V: Vision + text
- Image understanding
- Document OCR
- Chart analysis

### Tool Calling
- Native function calling support
- Agent-friendly architecture
- Structured output

---

## Recommended Usage for Executive Assistant

### Primary Model: **GLM-4.7** ‚≠ê (NEW!)
- **Best performance-to-price ratio** in Zhipu lineup
- Beats GPT-5.2 and Claude in several benchmarks
- Excellent for coding and complex reasoning
- Very competitive pricing ($0.60/$2.20 per 1M tokens)
- Open-weight (can self-host if needed)

### Secondary Model: **GLM-4.5-Air**
- Good balance of performance and cost
- Faster than GLM-4.5
- Suitable for production use
- Cheaper than GLM-4.7

### Development/Testing: **GLM-4 Flash**
- Free tier for testing
- Good for development
- Low-volume applications

### Recommended Configuration:

```yaml
llm:
  zhipu:
    default_model: glm-4.7            # Primary (best performance)
    fast_model: glm-4.5-air           # Balanced cost-effective
    reasoning_model: glm-4.7          # Same (excellent at reasoning)
    coding_model: glm-4.7             # Best-in-class coding
```

---

## Pros and Cons

### Pros:
- **GLM-4.7 beats GPT-5.2/Claude** - Top-tier performance at lower cost
- **GLM-4 Flash is free** - Great for development
- **Open-weight options** - GLM-4.7 can be self-hosted
- **Bilingual** - Excellent Chinese + English
- **Very competitive pricing** - $0.60/$2.20 (4√ó cheaper than GPT-4o)
- **Coding optimized** - GLM-4.7 is best-in-class for coding
- **38% improvement** - GLM-4.7 is significantly better than GLM-4.6

### Cons:
- **Chinese provider** - Potential latency issues outside China
- **Less mature ecosystem** - Fewer integrations than OpenAI/Anthropic
- **Documentation** - Mostly in Chinese (English docs improving)
- **Rate limits** - On free tier
- **Regional availability** - May have restrictions

---

## When to Use Zhipu GLM

### Use GLM when:
- **You want GPT-5.2 level performance at 4√ó lower cost** (GLM-4.7)
- Budget is a constraint (GLM-4 Flash is free)
- You need bilingual Chinese/English support
- You want to self-host (GLM-4.7 is open-weight)
- You're in Asia (lower latency)
- You need strong coding performance (GLM-4.7 is best-in-class)

### Avoid GLM when:
- You're outside Asia (latency issues)
- You need mature ecosystem and tooling
- You require extensive English documentation
- You need the absolute best performance (GPT-5/Claude Opus may be better)

---

## Integration Notes

### API Endpoint
- Base URL: `https://open.bigmodel.cn/api/paas/v4/`
- Compatible with OpenAI SDK (with modifications)
- Supports streaming responses

### Authentication
- API Key required
- Free tier available for testing
- Enterprise plans available

---

## Sources:
- [ZHIPU AI - Open Platform](https://open.bigmodel.cn/)
- [Product Pricing](https://bigmodel.cn/pricing)
- [GLM-4.7: Pricing, Context Window, Benchmarks](https://llm-stats.com/models/glm-4.7)
- [Zhipu AI releases GLM-4.7: Beating GPT-5.2 and Claude](https://www.reddit.com/r/singularity/comments/1pt38jt/zhipu_ai_releases_glm47_beating_gpt52_and_claude/)
- [Z.ai Releases GLM-4.7 Designed for Real-World Development](https://www.prnewswire.com/news-releases/zai-releases-glm-4-7-designed-for-real-world-development-environments-cementing-itself-as-chinas-openai-302649821.html)
- [What Is GLM-4.7? Features, Context Window, and Best Use Cases](https://macaron.im/blog/what-is-glm-4.7)
- [A Technical Analysis of GLM-4.7](https://medium.com/@leucopsis/a-technical-analysis-of-glm-4-7-db7fcc54210a)
- [Z.ai Open-Sources GLM-4.7](https://www.businesswire.com/news/home/20251223393714/en/Z.ai-Open-Sources-GLM-4-7-a-New-Generation-Large-Language-Model-Built-for-Real-Development-Workflows)
- [GLM-4.7 Released: What Does This Mean](https://www.cometapi.com/glm-4-7-released-what-does-this-mean-for-ai--intelligence)
- [GLM-4.5: Reasoning, Coding, and Agentic Abilities](https://z.ai/blog/glm-4.5)
