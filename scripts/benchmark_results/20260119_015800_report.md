# LLM Benchmark Report

**Generated:** 2026-01-19 01:58:00

**Total Tests:** 2

---

## Summary by Provider/Model

| Provider/Model | Tests | Avg Time (s) | Avg TTFT (s) | Avg tok/s | Avg Cost |
|---|---|---|---|---|---|
| openai/gpt-5-mini-2025-08-07 | 2 | 12.75 | 8.61 | 35 | $0.0006 |

---

## Detailed Results by Scenario

### simple_explanation

**Complexity:** simple

**Description:** Explain a concept briefly

**Expected Tools:** 

**Estimated Input Tokens:** ~1138



| Provider/Model | Time (s) | TTFT (s) | In Tok | Out Tok | tok/s | Cost | Status |
|---|---|---|---|---|---|---|---|
| openai/gpt-5-mini-2025-08-07 | 12.07 | 4.22 | 1138 | 824 | 68 | $0.0009 | ‚úÖ |


### simple_qa

**Complexity:** simple

**Description:** Simple factual question

**Expected Tools:** 

**Estimated Input Tokens:** ~1138



| Provider/Model | Time (s) | TTFT (s) | In Tok | Out Tok | tok/s | Cost | Status |
|---|---|---|---|---|---|---|---|
| openai/gpt-5-mini-2025-08-07 | 13.43 | 12.99 | 1138 | 29 | 2 | $0.0003 | ‚úÖ |


## Recommendations

‚ö° **Fastest Single Test:** openai/gpt-5-mini-2025-08-07

   - Scenario: simple_explanation

   - Time: 12.07s

   - TTFT: 4.22s

   - Speed: 68 tokens/second


üöÄ **Best Time to First Token:** openai/gpt-5-mini-2025-08-07

   - TTFT: 4.22s (critical for UX)


üí∞ **Best Value:** openai/gpt-5-mini-2025-08-07

   - Time: 12.07s

   - Cost: $0.0009 per call


üìä **GPT-5 Mini Analysis:**

- Average response time: 12.75s

- Average TTFT: 8.61s

- Tests completed: 2


‚ö†Ô∏è  **WARNING:** GPT-5 Mini is slow (12.75s average)!

   Consider switching to a faster model.

